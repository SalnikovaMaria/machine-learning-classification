# Учебный проект DST Skillfactory "PROJECT-3. EDA + Feature Engineering. Соревнование на Kaggle"

## Оглавление  
1. Описание проекта
2. Задачи проекта
3. Критерий выполнения проекта 
5. Результат
6. Выводы

### Описание проекта    
Представьте, что вы работаете дата-сайентистом в компании Booking. Одна из проблем компании — это нечестные отели, которые накручивают себе рейтинг. Одним из способов обнаружения таких отелей является построение модели, которая предсказывает рейтинг отеля. Если предсказания модели сильно отличаются от фактического результата, то, возможно, отель ведёт себя нечестно, и его стоит проверить.

Цель: Построить модель на основе алгоритмов машинного обучения, которая предсказывает рейтинг отеля.


### Задачи проекта:
* Ознакомиться с входными данными (датасет с информацией об отелях)
* Изучить пример машинного обучения (scikit-learn)
* Выполнить подготовку данных, которые будут использоваться для обучения модели
* Проверить эффективность предлагаемой модели, используя метрику MAPE
* Принять участие в соревнованиях на площадке kaggle.com


**Задача по подготовке данных стоит из следующих пунктов:**  

* Удаление строковых значений. Вам необходимо удалить из набора данных столбцы, данные в которых представлены не числами.
* Очистка от пропущенных значений. На предыдущем шаге мы делали это самым грубым из всех возможных способов, сейчас попробуйте подойти к процессу более гибко.
* Создание новых признаков. Мы попробуем создать новые столбцы с данными из существующих данных или с использованием внешних источников.
* Преобразование признаков. Применим различные преобразования над признаками вроде нормализации, стандартизации.
* Отбор признаков. Используем анализ мультиколлинеарности как шаг отбора признаков для модели.

### Критерий выполнения проекта 

Для успешного выполнения проекта необходимо получить значение метрики MAPE менее 13.5


### Результаты:  
MAPE 8.9


### Выводы:  
В РЕЗУЛЬТАТЕ РАБОТЫ НАД ДАННЫМ ПРОЕКТОМ:

* создала свою первую модель, основанную на алгоритмах машинного обучения;

* приняла участие в соревновании на Kaggle;

* поняла, как правильно «подготовить» данные, чтобы модель работала лучше.

